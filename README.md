# EMNIST-Visualizer

A clean, minimal **handwritten letter recognition** project built on **PyTorch** and **EMNIST (Letters)** â€” with training code, a lightweight CNN, and a simple browser-based drawing UI backed by a Flask API.

This repo is intentionally straightforward: no magic, no over-engineering. You can read every file and understand whatâ€™s happening.

---

## âœ¨ What this project does

* Trains a CNN to recognize **handwritten Aâ€“Z letters**
* Uses the **EMNIST Letters** dataset (26 classes)
* Exposes a **Flask backend** for inference
* Provides a **canvas-based frontend** to draw letters in your browser
* Saves the **best-performing model** during training

---

## ğŸ§  Model overview

* Input: `1 Ã— 28 Ã— 28` grayscale image
* Architecture:

  * 3Ã— Conv blocks (32 â†’ 64 â†’ 128 channels)
  * ReLU activations
  * MaxPooling
  * Adaptive average pooling
  * Fully connected classifier (26 classes)
* Loss: Crossâ€‘Entropy
* Optimizer: Adam
* LR Scheduler: StepLR

The architecture is intentionally compact and fast â€” perfect for realâ€‘time inference.

---

## ğŸ“ Project structure

```
.
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ dataset.py        # EMNIST dataloaders
â”‚   â”œâ”€â”€ model_arch.py     # CNN definition
â”‚   â””â”€â”€ train.py          # Training loop
â”‚
â”œâ”€â”€ backend.py             # Flask inference API
â”œâ”€â”€ frontend.py            # Local browser UI (canvas)
â”œâ”€â”€ emnist_model.pth       # Saved model (after training)
â””â”€â”€ README.md
```

---

## ğŸš€ Getting started

### 1. Install dependencies

```bash
pip install -r requirements.txt
```

---

### 2. Train the model

```bash
cd training
python train.py --epochs 5 --batch_size 64
```

During training:

* Validation accuracy is printed each epoch
* The **best model** is saved as `emnist_model.pth`

---

### 3. Start the backend

From the project root:

```bash
python backend.py
```

The backend:

* Loads `emnist_model.pth`
* Accepts base64 canvas images
* Returns predicted letter + confidence

---

### 4. Launch the frontend

```bash
python frontend.py
```

This opens a local webpage where you can:

* Draw a letter using your mouse / touch
* Send it to the backend
* See the predicted character instantly

---

## ğŸ”„ Inference pipeline 

Canvas â†’ Backend â†’ Model:

1. User draws on a **280Ã—280 canvas**
2. Image is:

   * Converted to grayscale
   * Resized to `28Ã—28`
   * Inverted (white background â†’ black)
   * Rotated & flipped to match EMNIST orientation
3. Normalized and fed to the CNN
4. Softmax â†’ predicted letter + confidence

The preprocessing is **critical** â€” EMNIST images are not oriented the same way as browser canvas drawings.

---

## ğŸ“Š Output format

Backend response:

```json
{
  "letter": "G",
  "confidence": 0.87
}
```
---

Feel free to fork, break, retrain, or extend it.
